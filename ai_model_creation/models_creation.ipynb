{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae25198",
   "metadata": {},
   "source": [
    "# OS Fingerprinting based on ML and p0f dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0c94776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import p0f_db_parser as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e320052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb270d",
   "metadata": {},
   "source": [
    "### Parse database and import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9ba34d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,column_names = parser.parse_database(\"p0f.fp\")\n",
    "df = pd.DataFrame(dataset,columns=column_names)\n",
    "del dataset\n",
    "del column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c695",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "41ab8755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_direction</th>\n",
       "      <th>os</th>\n",
       "      <th>version</th>\n",
       "      <th>initial_ttl</th>\n",
       "      <th>mss</th>\n",
       "      <th>window_size</th>\n",
       "      <th>window_scaling</th>\n",
       "      <th>tcp_options</th>\n",
       "      <th>quirk_df</th>\n",
       "      <th>quirk_id</th>\n",
       "      <th>quirk_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request</td>\n",
       "      <td>Linux</td>\n",
       "      <td>3.11 and newer</td>\n",
       "      <td>64</td>\n",
       "      <td>*</td>\n",
       "      <td>mss*20</td>\n",
       "      <td>10</td>\n",
       "      <td>mss,sok,ts,nop,ws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request</td>\n",
       "      <td>Linux</td>\n",
       "      <td>3.11 and newer</td>\n",
       "      <td>64</td>\n",
       "      <td>*</td>\n",
       "      <td>mss*20</td>\n",
       "      <td>7</td>\n",
       "      <td>mss,sok,ts,nop,ws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>request</td>\n",
       "      <td>Linux</td>\n",
       "      <td>3.1-3.10</td>\n",
       "      <td>64</td>\n",
       "      <td>*</td>\n",
       "      <td>mss*10</td>\n",
       "      <td>4</td>\n",
       "      <td>mss,sok,ts,nop,ws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request</td>\n",
       "      <td>Linux</td>\n",
       "      <td>3.1-3.10</td>\n",
       "      <td>64</td>\n",
       "      <td>*</td>\n",
       "      <td>mss*10</td>\n",
       "      <td>5</td>\n",
       "      <td>mss,sok,ts,nop,ws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request</td>\n",
       "      <td>Linux</td>\n",
       "      <td>3.1-3.10</td>\n",
       "      <td>64</td>\n",
       "      <td>*</td>\n",
       "      <td>mss*10</td>\n",
       "      <td>6</td>\n",
       "      <td>mss,sok,ts,nop,ws</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sig_direction     os         version  initial_ttl mss window_size  \\\n",
       "0       request  Linux  3.11 and newer           64   *      mss*20   \n",
       "1       request  Linux  3.11 and newer           64   *      mss*20   \n",
       "2       request  Linux        3.1-3.10           64   *      mss*10   \n",
       "3       request  Linux        3.1-3.10           64   *      mss*10   \n",
       "4       request  Linux        3.1-3.10           64   *      mss*10   \n",
       "\n",
       "  window_scaling        tcp_options  quirk_df  quirk_id  quirk_ts  \n",
       "0             10  mss,sok,ts,nop,ws         1         1         0  \n",
       "1              7  mss,sok,ts,nop,ws         1         1         0  \n",
       "2              4  mss,sok,ts,nop,ws         1         1         0  \n",
       "3              5  mss,sok,ts,nop,ws         1         1         0  \n",
       "4              6  mss,sok,ts,nop,ws         1         1         0  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Initial dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cb052282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variable name\n",
    "OutVar = list(df.columns)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b6ddb",
   "metadata": {},
   "source": [
    "### Encoding of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "cfac79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63c499",
   "metadata": {},
   "source": [
    "#### Filter Operating Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d122966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OSes\n",
    "df = df[df.os.isin(['Linux', 'Windows', 'Mac OS X', 'Solaris', 'OpenBSD', 'FreeBSD'])]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Drop version column\n",
    "df.drop('version', inplace=True, axis=1)\n",
    "\n",
    "df_test = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4e666",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e432aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# TTL, MSS & Windows size\n",
    "\n",
    "ttl_factor = 10\n",
    "\n",
    "array = df.to_numpy()\n",
    "ttl_i = df.columns.get_loc('initial_ttl')\n",
    "\n",
    "for row in array:\n",
    "    for i in range(1,ttl_factor+1):\n",
    "        new_row = row.copy()\n",
    "        new_row[ttl_i] = row[ttl_i] - i\n",
    "        \n",
    "        array = np.vstack((array, new_row))\n",
    "        \n",
    "df = pd.DataFrame(array, columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f18ef",
   "metadata": {},
   "source": [
    "#### TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "24a6b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTL\n",
    "# Numeric value (Â¿Standarization, Normalization?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e09dd",
   "metadata": {},
   "source": [
    "#### MSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "00bd8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSS\n",
    "# Categorical encoding\n",
    "\n",
    "encoder_mss = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c7abd",
   "metadata": {},
   "source": [
    "#### Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e387659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Size\n",
    "# Drop column\n",
    "\n",
    "class WindowSizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self \n",
    "\n",
    "    def transform(self,X):\n",
    "        return X.drop(X.columns[0],axis=1)\n",
    "    \n",
    "    def get_feature_names_out(self,names='window_size'):\n",
    "        # return [self.feature_name+str(i) for i in range(self.max_options)]\n",
    "        return []\n",
    "\n",
    "encoder_window_size = WindowSizeTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac872d9d",
   "metadata": {},
   "source": [
    "#### Windows Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "86414ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Scaling \n",
    "# Categorical encoding\n",
    "\n",
    "encoder_window_scaling = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# encoder_window_scaling.fit(df[['window_scaling']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed765f3",
   "metadata": {},
   "source": [
    "#### TCP options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9bd4c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Options\n",
    "# Custom transformer\n",
    "\n",
    "class TCPOptionsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.max_options = 0\n",
    "        self.feature_name = ''\n",
    "        self.classes = []\n",
    "        self.headers = {}\n",
    "        self.names_out = []\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X_2 = pd.DataFrame(X).reset_index(drop=True)\n",
    "        self.feature_name = X_2.columns[0]\n",
    "        for row in X_2[self.feature_name]:\n",
    "            values = row.split(',')\n",
    "            if len(values) > self.max_options:\n",
    "                self.max_options = len(values)\n",
    "            for v in values:\n",
    "                if v not in self.classes:\n",
    "                    self.classes.append(v)\n",
    "        self.headers = {self.feature_name+str(i):'*' for i in range(self.max_options)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_2 = pd.DataFrame(X).reset_index(drop=True)\n",
    "        X_2 = X_2.assign(**self.headers)\n",
    "        \n",
    "        row_i = 0\n",
    "        for row in X_2[self.feature_name]:\n",
    "            values = row.split(',')\n",
    "            values_len = len(values)\n",
    "            for i in range(values_len):\n",
    "                if i < self.max_options:\n",
    "                    X_2.at[row_i,self.feature_name+str(i)] = values[i]\n",
    "            row_i += 1\n",
    "            \n",
    "        X_2.drop(self.feature_name, inplace=True, axis=1)\n",
    "        \n",
    "        encoder2_tcp_options = OneHotEncoder(categories=[self.classes]*self.max_options,sparse=False,handle_unknown='ignore')\n",
    "        \n",
    "        encoder2_tcp_options.fit(X_2[list(self.headers.keys())])\n",
    "        result = encoder2_tcp_options.transform(X_2[list(self.headers.keys())])\n",
    "        \n",
    "        self.names_out = encoder2_tcp_options.get_feature_names_out()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_feature_names_out(self,names='tcp_options'):\n",
    "        # return [self.feature_name+str(i) for i in range(self.max_options)]\n",
    "        return self.names_out\n",
    "\n",
    "encoder_tcp_options = TCPOptionsTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d48d9",
   "metadata": {},
   "source": [
    "#### Quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c78c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quirks\n",
    "# Categorical encoding (already encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfb41b",
   "metadata": {},
   "source": [
    "#### Applying encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encodings\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "encoders = make_column_transformer(\n",
    "    (encoder_mss, ['mss']),\n",
    "    (encoder_window_size, ['window_size']),\n",
    "    (encoder_window_scaling, ['window_scaling']),\n",
    "    (encoder_tcp_options, ['tcp_options']),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "transformed = encoders.fit_transform(df)\n",
    "transformed_df = pd.DataFrame(\n",
    "    transformed,\n",
    "    columns=encoders.get_feature_names_out()\n",
    ")\n",
    "\n",
    "df = transformed_df\n",
    "\n",
    "# define output variable name\n",
    "OutVar = df.os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47eee06",
   "metadata": {},
   "source": [
    "#### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ec281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two datasets: requests and responses\n",
    "\n",
    "df_request = df[df.sig_direction.isin(['request'])].drop('sig_direction', axis=1)\n",
    "df_response = df[df.sig_direction.isin(['response'])].drop('sig_direction', axis=1)\n",
    "\n",
    "df_request.reset_index(inplace=True, drop=True)\n",
    "df_response.reset_index(inplace=True, drop=True)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be470b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_request.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_response.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509e59c",
   "metadata": {},
   "source": [
    "### Verify the classes ballance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_request[OutVar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_response[OutVar].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acecf5",
   "metadata": {},
   "source": [
    "### Get data as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea03bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request\n",
    "\n",
    "Ydata_request = df_request[OutVar].values                  # get values of features\n",
    "Xdata_request = df_request.drop(OutVar,axis = 1).values    # get output values\n",
    "\n",
    "print('Shape X data:', Xdata_request.shape)\n",
    "print('Shape Y data:',Ydata_request.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response\n",
    "\n",
    "Ydata_response = df_response[OutVar].values                  # get values of features\n",
    "Xdata_response = df_response.drop(OutVar,axis = 1).values    # get output values\n",
    "\n",
    "print('Shape X data:', Xdata_response.shape)\n",
    "print('Shape Y data:',Ydata_response.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959ba23",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request\n",
    "\n",
    "X_train_request, X_test_request, y_train_request, y_test_request = train_test_split(Xdata_request, Ydata_request,\n",
    "                                                                    stratify=Ydata_request, \n",
    "                                                                    test_size=0.10,\n",
    "                                                                    random_state=seed)\n",
    "\n",
    "# verify dimentions of data for training and test\n",
    "print('Shape X_train:', X_train_request.shape)\n",
    "print('Shape X_test:' , X_test_request.shape)\n",
    "print('Shape y_train:', y_train_request.shape)\n",
    "print('Shape y_test:' , y_test_request.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response\n",
    "\n",
    "X_train_response, X_test_response, y_train_response, y_test_response = train_test_split(Xdata_response, Ydata_response,\n",
    "                                                                        stratify=Ydata_response, \n",
    "                                                                        test_size=0.10,\n",
    "                                                                        random_state=seed)\n",
    "\n",
    "# verify dimentions of data for training and test\n",
    "print('Shape X_train:', X_train_response.shape)\n",
    "print('Shape X_test:' , X_test_response.shape)\n",
    "print('Shape y_train:', y_train_response.shape)\n",
    "print('Shape y_test:' , y_test_response.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b84adb",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac6edb",
   "metadata": {},
   "source": [
    "##### Classes balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69552527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If âbalancedâ, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(class_weight=option, classes=np.unique(y_data), y=y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w\n",
    "\n",
    "class_weights_request = set_weights(Ydata_request)\n",
    "class_weights_response = set_weights(Ydata_response)\n",
    "\n",
    "print(\"Request balance => \",class_weights_request)\n",
    "print(\"Response balance => \",class_weights_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e86d5",
   "metadata": {},
   "source": [
    "##### Classifiers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dec07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train as baseline classifiers\n",
    "classifiers_request = [\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(), # No random_state\n",
    "    LogisticRegression(n_jobs=-1,solver='lbfgs',random_state=seed,class_weight=class_weights_request),\n",
    "    MLPClassifier(hidden_layer_sizes= (30), random_state = seed, shuffle=False, solver='adam',activation='relu',batch_size=500, max_iter=5000),\n",
    "    DecisionTreeClassifier(random_state=seed,class_weight=class_weights_request),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights_request),\n",
    "    BaggingClassifier(n_jobs=-1,random_state=seed)\n",
    "]\n",
    "\n",
    "classifiers_response = [\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(), # No random_state\n",
    "    LogisticRegression(n_jobs=-1,solver='lbfgs',random_state=seed,class_weight=class_weights_response),\n",
    "    MLPClassifier(hidden_layer_sizes= (30), random_state = seed, shuffle=False, solver='adam',activation='relu',batch_size=500, max_iter=5000),\n",
    "    DecisionTreeClassifier(random_state=seed,class_weight=class_weights_response),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights_response),\n",
    "    BaggingClassifier(n_jobs=-1,random_state=seed)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4d01c",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and metrics (ACC, precision, recall, f1score) for a classifier\n",
    "def ML_baseline(cls, X_tr, y_tr, X_ts, y_ts, seed=42, classes=['0','1']):\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    cls_name = type(cls).__name__\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cls.fit(X_tr, y_tr) # TRAINING!\n",
    "    # print('\\n---->', \"training: %0.2f mins \\n\\n\" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    # predictions\n",
    "    y_pred  = cls.predict(X_ts)             # predict classes\n",
    "    y_probs = cls.predict_proba(X_ts)[:, 1] # predict probabilities of classes\n",
    "    cls_rep = classification_report(y_ts, y_pred, target_names=classes,\n",
    "                                    output_dict=True, digits=3)\n",
    "    # print classification report\n",
    "    #print(cls_rep)\n",
    "    \n",
    "    ACC       = accuracy_score(y_ts, y_pred)\n",
    "    #AUROC     = roc_auc_score(y_ts, y_probs) # this is working for 2-classes classification only!!!\n",
    "    precision = cls_rep['weighted avg']['precision']\n",
    "    recall    = cls_rep['weighted avg']['recall']\n",
    "    f1score   = cls_rep['weighted avg']['f1-score']  \n",
    "    \n",
    "    # print metrics\n",
    "    # print(\"\\n\", \"ACC=\", ACC, \"precision=\", precision, \"recall=\", recall, \"f1score=\",f1score)\n",
    "    \n",
    "    return cls, ACC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bfa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request\n",
    "\n",
    "# create a dataframe for ML baseline\n",
    "statistics_ML_request = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "\n",
    "classes_names = np.unique(Ydata_request)\n",
    "\n",
    "for cls in classifiers_request:\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train_request, y_train_request, X_test_request, y_test_request, seed=seed,classes=classes_names)\n",
    "    statistics_ML_request = statistics_ML_request.append({'Method': str(type(cls).__name__),\n",
    "                                                            'ACC': float(ACC),\n",
    "                                                            #'AUROC': float(AUROC),\n",
    "                                                            'precision': float(precision),\n",
    "                                                            'recall': float(recall),\n",
    "                                                            'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "statistics_ML_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response\n",
    "\n",
    "# create a dataframe for ML baseline\n",
    "statistics_ML_response = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "\n",
    "classes_names = np.unique(Ydata_response)\n",
    "\n",
    "for cls in classifiers_response:\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train_response, y_train_response, X_test_response, y_test_response, seed=seed,classes=classes_names)\n",
    "    statistics_ML_response = statistics_ML_response.concat({'Method': str(type(cls).__name__),\n",
    "                                                            'ACC': float(ACC),\n",
    "                                                            #'AUROC': float(AUROC),\n",
    "                                                            'precision': float(precision),\n",
    "                                                            'recall': float(recall),\n",
    "                                                            'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "statistics_ML_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ML.to_csv('ML_results.csv', index=False) # write to file the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20530004",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae085e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(encoders, '../persistance/encoders.joblib')\n",
    "encoders2 = load('../persistance/encoders.joblib')\n",
    "\n",
    "transformed2 = encoders2.transform(df_test)\n",
    "transformed_df_test = pd.DataFrame(\n",
    "    transformed2,\n",
    "    columns=encoders2.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b3721",
   "metadata": {},
   "source": [
    "### Try a better classifier for the best ML method\n",
    "\n",
    "We are using the best methods from baseline to find better hyperparameters for a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e75ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out best model was RF:\n",
    "cls=RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the parameters\n",
    "cls.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train with different params\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=10, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=20, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=50, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=200, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=500, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfeff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_ML2 = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "df_ML2\n",
    "\n",
    "for cls in classifiers:\n",
    "    print(\"\\n**********************************\\n\", cls)\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train, y_train, X_test, y_test, seed=seed,classes=classes_names)\n",
    "    df_ML2 = df_ML2.append({'Method': str(type(cls).__name__)+'-NoTrees='+str(cls.get_params()['n_estimators']),\n",
    "                            'ACC': float(ACC),\n",
    "                            #'AUROC': float(AUROC),\n",
    "                            'precision': float(precision),\n",
    "                            'recall': float(recall),\n",
    "                            'f1-score': float(f1score)}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809acf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML2.to_csv('ML_results_best1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e116f",
   "metadata": {},
   "source": [
    "### Grid search - search for the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsx = {'bootstrap': [True, False],\n",
    "           'max_depth': [10, 20, 30, 40, 50, None],\n",
    "           'max_features': ['auto', 'sqrt'],\n",
    "           'min_samples_leaf': [1, 2, 4],\n",
    "           'min_samples_split': [2, 5, 10],\n",
    "           'n_estimators': [50]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest= RandomForestClassifier(random_state=seed,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d095809",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridF = GridSearchCV(forest, paramsx, cv = 3, verbose = 2, n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestF.best_params_ # params of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac956f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(model, x_test, y_test):\n",
    "    labels = np.unique(y_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print (accuracy)\n",
    "    cm = confusion_matrix(y_test,y_pred, labels=labels)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = bestF.best_estimator_ # the best model from grid search\n",
    "\n",
    "evaluate(best_grid,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5624f",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ACC\n",
    "y_pred=clf.predict(X_test)\n",
    "print(list(clf.classes_))\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=df.columns[:-1]).sort_values(ascending=False)\n",
    "feature_imp[:30]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641d8269f063d1dd6b8e5de571a838aa2a022ace140349eaf6f3c271c01e6aeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
