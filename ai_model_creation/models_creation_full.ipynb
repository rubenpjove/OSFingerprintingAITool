{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae25198",
   "metadata": {},
   "source": [
    "# Prediction of OS type using Machine Learning based on OS fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import p0f_db_parser as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506922c",
   "metadata": {},
   "source": [
    "### Read dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73162f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb270d",
   "metadata": {},
   "source": [
    "### Parse database and import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba34d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,column_names = parser.parse_database(\"p0f.fp\")\n",
    "df = pd.DataFrame(dataset,columns=column_names)\n",
    "del dataset\n",
    "del column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c695",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0a635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# header = names of columns\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of features (X)\n",
    "print(\"Number of features = \", len(list(df.columns))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923817f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output name\n",
    "print(\"Output=\", list(df.columns)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb052282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variable name\n",
    "OutVar = list(df.columns)[1]\n",
    "print(OutVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9139c9",
   "metadata": {},
   "source": [
    "### Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCheckings(df):\n",
    "    # Check the number of data points in the data set\n",
    "    print(\"\\nData points =\", len(df))\n",
    "    \n",
    "    # Check the number of columns in the data set\n",
    "    print(\"\\nColumns (output + features)=\",len(df.columns))\n",
    "    \n",
    "    # Check the data types\n",
    "    print(\"\\nData types =\", df.dtypes.unique())\n",
    "    \n",
    "    # List of values per column\n",
    "    print()\n",
    "    for column in df.columns:\n",
    "        print(column + \" -> \")\n",
    "        print(df[column].value_counts())\n",
    "        print()\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print('\\n')\n",
    "    df.describe()\n",
    "    \n",
    "    # print names of columns\n",
    "    print('Column Names:\\n', df.columns)\n",
    "    \n",
    "    # see if there are categorical data\n",
    "    print(\"\\nCategorical features:\", df.select_dtypes(include=['O']).columns.tolist())\n",
    "    \n",
    "    # Check NA values\n",
    "    # Check any number of columns with NaN\n",
    "    print(\"\\nColumns with NaN: \", df.isnull().any().sum(), ' / ', len(df.columns))\n",
    "\n",
    "    # Check any number of data points with NaN\n",
    "    print(\"\\nNumber of data points with NaN:\", df.isnull().any(axis=1).sum(), ' / ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCheckings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335faba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape before removing duplicates = ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6005fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates!\n",
    "\n",
    "df.drop_duplicates(keep=False, inplace=True)\n",
    "print('Shape after removing duplicates=', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b6ddb",
   "metadata": {},
   "source": [
    "### Encoding of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OSes\n",
    "df = df[df.os.isin(['Linux', 'Windows', 'Mac OS X', 'Solaris', 'OpenBSD', 'FreeBSD'])]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Drop version column\n",
    "df.drop('version', inplace=True, axis=1)\n",
    "\n",
    "# Drop signature direction column\n",
    "# df.drop('sig_direction', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# TTL, MSS & Windows size\n",
    "\n",
    "ttl_factor = 10\n",
    "\n",
    "array = df.to_numpy()\n",
    "ttl_i = df.columns.get_loc('initial_ttl')\n",
    "\n",
    "for row in array:\n",
    "    for i in range(1,ttl_factor+1):\n",
    "        new_row = row.copy()\n",
    "        new_row[ttl_i] = row[ttl_i] - i\n",
    "        \n",
    "        array = np.vstack((array, new_row))\n",
    "        \n",
    "df = pd.DataFrame(array, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTL\n",
    "# Numeric value (Â¿Normalization?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSS\n",
    "# Categorical encoding\n",
    "\n",
    "encoder_mss = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Size\n",
    "# ??????????\n",
    "\n",
    "df.drop('window_size', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86414ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Scaling \n",
    "# Categorical encoding\n",
    "\n",
    "encoder_window_scaling = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# encoder_window_scaling.fit(df[['window_scaling']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Options\n",
    "# Custom transformer\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class TCPOptionsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_name):\n",
    "        self.feature_name = feature_name\n",
    "        self.max_options = 0\n",
    "        self.classes = []\n",
    "        self.headers = {}\n",
    "    \n",
    "    def fit(self, X):\n",
    "        column = X[self.feature_name]\n",
    "        for row in column:\n",
    "            values = row.split(',')\n",
    "            if len(values) > self.max_options:\n",
    "                self.max_options = len(values)\n",
    "            for v in values:\n",
    "                if v not in self.classes:\n",
    "                    self.classes.append(v)\n",
    "        self.headers = {self.feature_name+str(i):'*' for i in range(self.max_options)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_2 = X.copy()\n",
    "        X_2 = X_2.assign(**self.headers)\n",
    "        \n",
    "        row_i = 0\n",
    "        for row in X_2[self.feature_name]:\n",
    "            values = row.split(',')\n",
    "            values_len = len(values)\n",
    "            for i in range(values_len):\n",
    "                if i < self.max_options:\n",
    "                    X_2.at[row_i,self.feature_name+str(i)] = values[i]\n",
    "            row_i += 1\n",
    "            \n",
    "        X_2.drop(self.feature_name, inplace=True, axis=1)\n",
    "        return X_2\n",
    "    \n",
    "    def get_feature_names_out(self,names):\n",
    "        return [self.feature_name+str(i) for i in range(self.max_options)]\n",
    "\n",
    "encoder_tcp_options = TCPOptionsTransformer('tcp_options')\n",
    "df = encoder_tcp_options.fit_transform(df)\n",
    "\n",
    "encoder2_tcp_options = OneHotEncoder(categories=[encoder_tcp_options.classes]*encoder_tcp_options.max_options,sparse=False,handle_unknown='ignore')\n",
    "\n",
    "# encoder2_tcp_options.fit(df[list(encoder_tcp_options.headers.keys())])\n",
    "# encoder2_tcp_options.transform(df[list(encoder_tcp_options.headers.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quirks\n",
    "# Categorical encoding (already encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encodings\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "df.reset_index(inplace=True, drop=True) \n",
    "\n",
    "encoders = make_column_transformer(\n",
    "    (encoder_mss, ['mss']),\n",
    "    (encoder_window_scaling, ['window_scaling']),\n",
    "    (encoder2_tcp_options, make_column_selector(pattern='tcp_options')),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False,\n",
    "    n_jobs=1)\n",
    "\n",
    "transformed = encoders.fit_transform(df)\n",
    "transformed_df = pd.DataFrame(\n",
    "    transformed,\n",
    "    columns=encoders.get_feature_names_out()\n",
    ")\n",
    "\n",
    "df = transformed_df\n",
    "\n",
    "# define output variable name\n",
    "OutVar = df.os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "df = df[df.sig_direction.isin(['request'])]\n",
    "df.drop('sig_direction', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0821b",
   "metadata": {},
   "source": [
    "### Remove near zero variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDataFrame(df, OutVar):\n",
    "    # get X, Y data and column names from df\n",
    "    print('\\n-> Get X & Y data, Features list')\n",
    "    print('Shape', df.shape)\n",
    "    \n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:', Ydata.shape)\n",
    "    \n",
    "    # return data for X and Y, feature names as list\n",
    "    print('Done!')\n",
    "    return (Xdata, Ydata, list(ds_X.columns))\n",
    "\n",
    "def Remove0VarCols(df, OutVar):\n",
    "    Xdata, Ydata, Features = getDataFromDataFrame(df,OutVar=OutVar)# out var = Class \n",
    "    print('\\n-> Remove zero variance features')\n",
    "    # print('Initial features:', Features)\n",
    "    selector= VarianceThreshold()\n",
    "    Xdata = selector.fit_transform(Xdata)\n",
    "    # Selected features\n",
    "    SelFeatures = []\n",
    "    for i in selector.get_support(indices=True):\n",
    "        SelFeatures.append(Features[i])\n",
    "    print('Removed features:',list(set(Features) - set(SelFeatures)))\n",
    "    \n",
    "    # create the resulted dataframe\n",
    "    df = pd.DataFrame(Xdata,columns=SelFeatures)\n",
    "    df[OutVar] = Ydata # add class column\n",
    "    # print('Final columns:', list(df.columns))\n",
    "    print('Done!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aaf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Remove0VarCols(df, OutVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dimension AFTER removing features\n",
    "print(\"Dataset dimension AFTER removing near zero variance features=\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509e59c",
   "metadata": {},
   "source": [
    "### Verify the classes ballance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[OutVar].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acecf5",
   "metadata": {},
   "source": [
    "### Get data as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea03bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X and Y\n",
    "Ydata = df[OutVar].values                  # get values of features\n",
    "Xdata = df.drop(OutVar,axis = 1).values    # get output values\n",
    "\n",
    "print('Shape X data:', Xdata.shape)\n",
    "print('Shape Y data:',Ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82d60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959ba23",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata,\n",
    "                                                    stratify=Ydata, \n",
    "                                                    test_size=0.10,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify dimentions of data for training and test\n",
    "print('Shape X_train:', X_train.shape)\n",
    "print('Shape X_test:' , X_test.shape)\n",
    "print('Shape y_train:', y_train.shape)\n",
    "print('Shape y_test:' , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b84adb",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb80c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If âbalancedâ, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(class_weight=option, classes=np.unique(y_data), y=y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b46def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = set_weights(Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf52d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes=\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dec07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train as baseline classifiers\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(), # No random_state\n",
    "    LogisticRegression(n_jobs=-1,solver='lbfgs',random_state=seed,class_weight=class_weights),\n",
    "    MLPClassifier(hidden_layer_sizes= (30), random_state = seed, shuffle=False, solver='adam',activation='relu',batch_size=500, max_iter=5000),\n",
    "    DecisionTreeClassifier(random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    # BaggingClassifier(n_jobs=-1,random_state=seed)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and metrics (ACC, precision, recall, f1score) for a classifier\n",
    "def ML_baseline(cls, X_tr, y_tr, X_ts, y_ts, seed=42, classes=['0','1']):\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    cls_name = type(cls).__name__\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cls.fit(X_tr, y_tr) # TRAINING!\n",
    "    print('\\n---->', \"training: %0.2f mins \\n\\n\" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    # predictions\n",
    "    y_pred  = cls.predict(X_ts)             # predict classes\n",
    "    y_probs = cls.predict_proba(X_ts)[:, 1] # predict probabilities of classes\n",
    "    cls_rep = classification_report(y_ts, y_pred, target_names=classes,\n",
    "                                    output_dict=True, digits=3)\n",
    "    # print classification report\n",
    "    #print(cls_rep)\n",
    "    \n",
    "    ACC       = accuracy_score(y_ts, y_pred)\n",
    "    #AUROC     = roc_auc_score(y_ts, y_probs) # this is working for 2-classes classification only!!!\n",
    "    precision = cls_rep['weighted avg']['precision']\n",
    "    recall    = cls_rep['weighted avg']['recall']\n",
    "    f1score   = cls_rep['weighted avg']['f1-score']  \n",
    "    \n",
    "    # print metrics\n",
    "    print(\"\\n\", \"ACC=\", ACC, \"precision=\", precision, \"recall=\", recall, \"f1score=\",f1score)\n",
    "    \n",
    "    return cls, ACC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bfa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_ML = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "\n",
    "classes_names = np.unique(Ydata)\n",
    "\n",
    "for cls in classifiers:\n",
    "    print(\"\\n**********************************\"+type(cls).__name__+\"**********************************\")\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train, y_train, X_test, y_test, seed=seed,classes=classes_names)\n",
    "    df_ML = df_ML.append({'Method': str(type(cls).__name__),\n",
    "                          'ACC': float(ACC),\n",
    "                          #'AUROC': float(AUROC),\n",
    "                          'precision': float(precision),\n",
    "                          'recall': float(recall),\n",
    "                          'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.to_csv('ML_results.csv', index=False) # write to file the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b3721",
   "metadata": {},
   "source": [
    "### Try a better classifier for the best ML method\n",
    "\n",
    "We are using the best methods from baseline to find better hyperparameters for a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e75ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out best model was RF:\n",
    "cls=RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the parameters\n",
    "cls.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train with different params\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=10, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=20, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=50, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=200, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_estimators=500, n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfeff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_ML2 = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "df_ML2\n",
    "\n",
    "for cls in classifiers:\n",
    "    print(\"\\n**********************************\\n\", cls)\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train, y_train, X_test, y_test, seed=seed,classes=classes_names)\n",
    "    df_ML2 = df_ML2.append({'Method': str(type(cls).__name__)+'-NoTrees='+str(cls.get_params()['n_estimators']),\n",
    "                            'ACC': float(ACC),\n",
    "                            #'AUROC': float(AUROC),\n",
    "                            'precision': float(precision),\n",
    "                            'recall': float(recall),\n",
    "                            'f1-score': float(f1score)}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809acf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML2.to_csv('ML_results_best1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(cls.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e116f",
   "metadata": {},
   "source": [
    "### Grid search - search for the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsx = {'bootstrap': [True, False],\n",
    "           'max_depth': [10, 20, 30, 40, 50, None],\n",
    "           'max_features': ['auto', 'sqrt'],\n",
    "           'min_samples_leaf': [1, 2, 4],\n",
    "           'min_samples_split': [2, 5, 10],\n",
    "           'n_estimators': [50]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest= RandomForestClassifier(random_state=seed,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d095809",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridF = GridSearchCV(forest, paramsx, cv = 3, verbose = 2, n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestF.best_params_ # params of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39274d92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac956f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    y_pred = model.predict(test_features)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print (accuracy)\n",
    "    print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = bestF.best_estimator_ # the best model from grid search\n",
    "\n",
    "evaluate(best_grid,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a615181",
   "metadata": {},
   "source": [
    "Classes= {'Android': 14.665116279069768, 'BSD': 2.649950973525704, 'Linux': 0.2654263826921458, 'Solaris': 7.6808769792935445, 'Windows': 0.5636396138720057, 'iOS': 2.195682451253482, 'macOS': 2.3413366336633663}\n",
    "\n",
    "Linux      142548\n",
    "Windows     67128\n",
    "iOS         17232\n",
    "macOS       16160\n",
    "BSD         14278\n",
    "Solaris      4926\n",
    "Android      2580"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5624f",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ACC\n",
    "y_pred=clf.predict(X_test)\n",
    "print(list(clf.classes_))\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=df.columns[:-1]).sort_values(ascending=False)\n",
    "feature_imp[:30]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641d8269f063d1dd6b8e5de571a838aa2a022ace140349eaf6f3c271c01e6aeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
