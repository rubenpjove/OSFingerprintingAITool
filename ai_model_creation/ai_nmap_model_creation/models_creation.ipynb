{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae25198",
   "metadata": {},
   "source": [
    "# OS Fingerprinting based on ML and nmap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c94776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e320052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb270d",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba34d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39149/3350788483.py:1: DtypeWarning: Columns (7,9,10,30,39,41,45,46,47,48,50,52,56,57,58,59,61,63,67,68,69,70,72,81,83,85,89,90,91,92,94,96,100,101,102,103,105,106,115,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c695",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ab8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Initial dataset\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb052282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variable name\n",
    "# OutVar = list(df.columns)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c9b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf72b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DataCheckings(df):\n",
    "#     # Check the number of data points in the data set\n",
    "#     print(\"\\nData points =\", len(df))\n",
    "    \n",
    "#     # Check the number of columns in the data set\n",
    "#     print(\"\\nColumns (output + features)=\",len(df.columns))\n",
    "    \n",
    "#     # Check the data types\n",
    "#     print(\"\\nData types =\", df.dtypes.unique())\n",
    "    \n",
    "#     # List of values per column\n",
    "#     print()\n",
    "#     for column in df.columns:\n",
    "#         print(column + \" -> \")\n",
    "#         print(df[column].value_counts())\n",
    "#         print()\n",
    "    \n",
    "#     # Dataset statistics\n",
    "#     print('\\n')\n",
    "#     df.describe()\n",
    "    \n",
    "#     # print names of columns\n",
    "#     print('Column Names:\\n', df.columns)\n",
    "    \n",
    "#     # see if there are categorical data\n",
    "#     print(\"\\nCategorical features:\", df.select_dtypes(include=['O']).columns.tolist())\n",
    "    \n",
    "#     # Check NA values\n",
    "#     # Check any number of columns with NaN\n",
    "#     print(\"\\nColumns with NaN: \", df.isnull().any().sum(), ' / ', len(df.columns))\n",
    "\n",
    "#     # Check any number of data points with NaN\n",
    "#     print(\"\\nNumber of data points with NaN:\", df.isnull().any(axis=1).sum(), ' / ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c41e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataCheckings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "681757b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Class.OSfamily',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W1','OPS.O1',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W2','OPS.O2',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W3','OPS.O3',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W4','OPS.O4',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W5','OPS.O5',\n",
    "         'T1.R', 'T1.DF', 'T1.TG','WIN.W6','OPS.O6',\n",
    "         'T2.R', 'T2.DF', 'T2.TG', 'T2.W',  'T2.O',   \n",
    "         'T3.R', 'T3.DF', 'T3.TG', 'T3.W',  'T3.O',   \n",
    "         'T4.R', 'T4.DF', 'T4.TG', 'T4.W',  'T4.O',   \n",
    "         'T5.R', 'T5.DF', 'T5.TG', 'T5.W',  'T5.O',   \n",
    "         'T6.R', 'T6.DF', 'T6.TG', 'T6.W',  'T6.O',   \n",
    "         'T7.R', 'T7.DF', 'T7.TG', 'T7.W',  'T7.O'\n",
    "         ]]\n",
    "\n",
    "df.columns = ['os',\n",
    "         '1.R', '1.DF', '1.TG','1.W','1.O',\n",
    "         '2.R', '2.DF', '2.TG','2.W','2.O',\n",
    "         '3.R', '3.DF', '3.TG','3.W','3.O',\n",
    "         '4.R', '4.DF', '4.TG','4.W','4.O',\n",
    "         '5.R', '5.DF', '5.TG','5.W','5.O',\n",
    "         '6.R', '6.DF', '6.TG','6.W','6.O',\n",
    "         '7.R', '7.DF', '7.TG', '7.W',  '7.O',   \n",
    "         '8.R', '8.DF', '8.TG', '8.W',  '8.O',   \n",
    "         '9.R', '9.DF', '9.TG', '9.W',  '9.O',   \n",
    "         '10.R', '10.DF', '10.TG', '10.W', '10.O',   \n",
    "         '11.R', '11.DF', '11.TG', '11.W', '11.O',   \n",
    "         '12.R', '12.DF', '12.TG', '12.W', '12.O'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765e098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = df.to_dict('records')\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e6a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_list = []\n",
    "\n",
    "for row in df_list:\n",
    "    for i in range(1,13):\n",
    "        if row[str(i)+'.R'] == \"Y\":\n",
    "            new_row = {}\n",
    "            istr = str(i)\n",
    "            new_row['os'] = row['os']\n",
    "            new_row['initial_ttl'] = row[istr+'.TG']\n",
    "            new_row['window_size'] = row[istr+'.W']\n",
    "            new_row['quirk_df'] = 1 if row[istr+'.DF'] == \"Y\" else 0\n",
    "            new_row['quirk_ts'] = 0\n",
    "            new_row['mss'] = '*'\n",
    "            new_row['window_scaling'] = '*'\n",
    "            \n",
    "            options = str(row[istr+'.O'])\n",
    "            options = options.split(',')\n",
    "            final_options = []\n",
    "            for options_item in options:\n",
    "                if options_item in [\"eol\",\"nop\",\"sok\"]:\n",
    "                    final_options.append(options_item)\n",
    "                if \"mss\" in options_item :\n",
    "                    new_row['mss'] = options_item.split('.')[1]\n",
    "                    final_options.append(\"mss\")\n",
    "                if \"ws\" in options_item:\n",
    "                    new_row['window_scaling'] = options_item.split('.')[1]\n",
    "                    final_options.append(\"ws\")\n",
    "                if \"ts\" in options_item:\n",
    "                    new_row['quirk_ts'] = 1 if options_item.split('.')[1][0] == '0' else 0\n",
    "                    final_options.append(\"ts\")\n",
    "                    \n",
    "            new_row['tcp_options'] = ','.join(final_options)\n",
    "            new_df_list.append(new_row)\n",
    "            \n",
    "del df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abda0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_df_list)\n",
    "del new_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6765c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing duplicates =  (2689933, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before removing duplicates = ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68510fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates= (1105, 8)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(keep=False, inplace=True)\n",
    "print('Shape after removing duplicates=', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c425d7d",
   "metadata": {},
   "source": [
    "### Encoding of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfac79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from ai_model_creation.ai_nmap_model_creation.transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63c499",
   "metadata": {},
   "source": [
    "#### Filter Operating Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d122966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OSes\n",
    "# df = df[df.os.isin(['Linux', 'Windows', 'Mac OS X', 'Solaris', 'OpenBSD', 'FreeBSD'])]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4e666",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e432aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# TTL, MSS & Windows size\n",
    "\n",
    "# ttl_factor = 10\n",
    "\n",
    "# array = df.to_numpy()\n",
    "# ttl_i = df.columns.get_loc('initial_ttl')\n",
    "\n",
    "# for row in array:\n",
    "#     for i in range(1,ttl_factor+1):\n",
    "#         new_row = row.copy()\n",
    "#         new_row[ttl_i] = row[ttl_i] - i\n",
    "        \n",
    "#         array = np.vstack((array, new_row))\n",
    "        \n",
    "# df = pd.DataFrame(array, columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f18ef",
   "metadata": {},
   "source": [
    "#### TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a6b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTL\n",
    "# Numeric value (¿Standarization, Normalization?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e09dd",
   "metadata": {},
   "source": [
    "#### MSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00bd8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSS\n",
    "# Categorical encoding\n",
    "\n",
    "encoder_mss = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c7abd",
   "metadata": {},
   "source": [
    "#### Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e387659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Size\n",
    "# Drop column\n",
    "\n",
    "encoder_window_size = WindowSizeTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac872d9d",
   "metadata": {},
   "source": [
    "#### Windows Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86414ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Scaling \n",
    "# Categorical encoding\n",
    "\n",
    "encoder_window_scaling = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# encoder_window_scaling.fit(df[['window_scaling']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed765f3",
   "metadata": {},
   "source": [
    "#### TCP options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd4c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Options\n",
    "# Custom transformer\n",
    "\n",
    "encoder_tcp_options = TCPOptionsTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d48d9",
   "metadata": {},
   "source": [
    "#### Quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c78c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quirks\n",
    "# Categorical encoding (already encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfb41b",
   "metadata": {},
   "source": [
    "#### Applying encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fa1e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encodings\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "encoders = make_column_transformer(\n",
    "    (encoder_mss, ['mss']),\n",
    "    (encoder_window_size, ['window_size']),\n",
    "    (encoder_window_scaling, ['window_scaling']),\n",
    "    (encoder_tcp_options, ['tcp_options']),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "transformed = encoders.fit_transform(df)\n",
    "transformed_df = pd.DataFrame(\n",
    "    transformed,\n",
    "    columns=encoders.get_feature_names_out()\n",
    ")\n",
    "\n",
    "df = transformed_df\n",
    "\n",
    "# define output variable name\n",
    "OutVar = df.os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b02367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d1199c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linux      365\n",
       "Windows    308\n",
       "macOS       44\n",
       "iOS         43\n",
       "Solaris     42\n",
       "FreeBSD     35\n",
       "Android     20\n",
       "OpenBSD     19\n",
       "NetBSD       9\n",
       "Name: os, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[OutVar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bea03bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X data: (885, 249)\n",
      "Shape Y data: (885,)\n"
     ]
    }
   ],
   "source": [
    "# Request\n",
    "\n",
    "Ydata = df[OutVar].values                  # get values of features\n",
    "Xdata = df.drop(OutVar,axis = 1).values    # get output values\n",
    "\n",
    "print('Shape X data:', Xdata.shape)\n",
    "print('Shape Y data:',Ydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959ba23",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "144da96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d604e432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train: (796, 249)\n",
      "Shape X_test: (89, 249)\n",
      "Shape y_train: (796,)\n",
      "Shape y_test: (89,)\n"
     ]
    }
   ],
   "source": [
    "# Request\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata,\n",
    "                                                    stratify=Ydata, \n",
    "                                                    test_size=0.10,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "# verify dimentions of data for training and test\n",
    "print('Shape X_train:', X_train.shape)\n",
    "print('Shape X_test:' , X_test.shape)\n",
    "print('Shape y_train:', y_train.shape)\n",
    "print('Shape y_test:' , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b84adb",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "306a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac6edb",
   "metadata": {},
   "source": [
    "##### Classes balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69552527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request balance =>  {'Android': 4.916666666666667, 'FreeBSD': 2.8095238095238093, 'Linux': 0.2694063926940639, 'NetBSD': 10.925925925925926, 'OpenBSD': 5.175438596491228, 'Solaris': 2.3412698412698414, 'Windows': 0.31926406926406925, 'iOS': 2.2868217054263567, 'macOS': 2.234848484848485}\n"
     ]
    }
   ],
   "source": [
    "def set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(class_weight=option, classes=np.unique(y_data), y=y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w\n",
    "\n",
    "class_weights = set_weights(Ydata)\n",
    "\n",
    "print(\"Request balance => \",class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e86d5",
   "metadata": {},
   "source": [
    "##### Classifiers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32dec07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train as baseline classifiers\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(), # No random_state\n",
    "    LogisticRegression(n_jobs=-1,solver='lbfgs',random_state=seed,class_weight=class_weights),\n",
    "    MLPClassifier(hidden_layer_sizes= (30), random_state = seed, shuffle=False, solver='adam',activation='relu',batch_size=500, max_iter=5000),\n",
    "    DecisionTreeClassifier(random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    BaggingClassifier(n_jobs=-1,random_state=seed)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4d01c",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472a2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and metrics (ACC, precision, recall, f1score) for a classifier\n",
    "def ML_baseline(cls, X_tr, y_tr, X_ts, y_ts, seed=42, classes=['0','1']):\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    cls_name = type(cls).__name__\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cls.fit(X_tr, y_tr) # TRAINING!\n",
    "    # print('\\n---->', \"training: %0.2f mins \\n\\n\" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    # predictions\n",
    "    y_pred  = cls.predict(X_ts)             # predict classes\n",
    "    y_probs = cls.predict_proba(X_ts)[:, 1] # predict probabilities of classes\n",
    "    cls_rep = classification_report(y_ts, y_pred, target_names=classes,\n",
    "                                    output_dict=True, digits=3)\n",
    "    # print classification report\n",
    "    #print(cls_rep)\n",
    "    \n",
    "    ACC       = accuracy_score(y_ts, y_pred)\n",
    "    #AUROC     = roc_auc_score(y_ts, y_probs) # this is working for 2-classes classification only!!!\n",
    "    precision = cls_rep['weighted avg']['precision']\n",
    "    recall    = cls_rep['weighted avg']['recall']\n",
    "    f1score   = cls_rep['weighted avg']['f1-score']  \n",
    "    \n",
    "    # print metrics\n",
    "    # print(\"\\n\", \"ACC=\", ACC, \"precision=\", precision, \"recall=\", recall, \"f1score=\",f1score)\n",
    "    \n",
    "    return cls, ACC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06ce0263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ruben/AIFingerprintingTool/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
      "/tmp/ipykernel_39149/3929213877.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models_ML = models_ML.append({'Method': str(type(cls).__name__),\n"
     ]
    }
   ],
   "source": [
    "# Response\n",
    "\n",
    "# create a dataframe for ML baseline\n",
    "statistics_ML = pd.DataFrame(columns=['Method', 'ACC','precision' ,'recall' ,'f1-score' ])\n",
    "models_ML = pd.DataFrame(columns=['Method', 'Model' ])\n",
    "\n",
    "classes_names = np.unique(Ydata)\n",
    "\n",
    "for cls in classifiers:\n",
    "    cls_fit, ACC, precision,recall,f1score=ML_baseline(cls, X_train, y_train, X_test, y_test, seed=seed,classes=classes_names)\n",
    "    \n",
    "    statistics_ML = statistics_ML.append({'Method': str(type(cls).__name__),\n",
    "                                                            'ACC': float(ACC),\n",
    "                                                            #'AUROC': float(AUROC),\n",
    "                                                            'precision': float(precision),\n",
    "                                                            'recall': float(recall),\n",
    "                                                            'f1-score': float(f1score)}, ignore_index=True)\n",
    "    \n",
    "    models_ML = models_ML.append({'Method': str(type(cls).__name__),\n",
    "                                                    'Model' : cls_fit}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c809ac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>ACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.817769</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.709844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.755377</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.758809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.812306</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.756722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.774836</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.788025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.759765</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.743567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.786454</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.781056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.828777</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.806547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Method       ACC precision    recall  f1-score\n",
       "0                  GaussianNB  0.662921  0.817769  0.662921  0.709844\n",
       "1  LinearDiscriminantAnalysis  0.775281  0.755377  0.775281  0.758809\n",
       "2          LogisticRegression  0.730337  0.812306  0.730337  0.756722\n",
       "3               MLPClassifier  0.808989  0.774836  0.808989  0.788025\n",
       "4      DecisionTreeClassifier  0.741573  0.759765  0.741573  0.743567\n",
       "5      RandomForestClassifier  0.786517  0.786454  0.786517  0.781056\n",
       "6           BaggingClassifier  0.808989  0.828777  0.808989  0.806547"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20530004",
   "metadata": {},
   "source": [
    "### Export transformers & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae085e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../persistence/nmap_classifier.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Transformers\n",
    "dump(encoders, '../../persistence/nmap/nmap_encoders.joblib')\n",
    "\n",
    "# Models\n",
    "dump(models_ML.Model.values[6],'../../persistence/nmap/nmap_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641d8269f063d1dd6b8e5de571a838aa2a022ace140349eaf6f3c271c01e6aeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
