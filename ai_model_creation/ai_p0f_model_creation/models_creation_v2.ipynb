{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae25198",
   "metadata": {},
   "source": [
    "# OS Fingerprinting based on ML and p0f dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import p0f_db_parser as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb270d",
   "metadata": {},
   "source": [
    "### Parse database and import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba34d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,column_names = parser.parse_database(\"p0f.fp\")\n",
    "df = pd.DataFrame(dataset,columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c695",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb052282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCheckings(df):\n",
    "    # Check the number of data points in the data set\n",
    "    print(\"\\nData points =\", len(df))\n",
    "    \n",
    "    # Check the number of columns in the data set\n",
    "    print(\"\\nColumns (output + features)=\",len(df.columns))\n",
    "    \n",
    "    # Check the data types\n",
    "    print(\"\\nData types =\", df.dtypes.unique())\n",
    "\n",
    "    # Check the number of duplicates\n",
    "    print(\"Number of duplicates: \", df.duplicated().sum())\n",
    "\n",
    "    # Dataset statistics\n",
    "    print('\\n')\n",
    "    df.describe()\n",
    "    \n",
    "    # print names of columns\n",
    "    print('Column Names:\\n', df.columns)\n",
    "    \n",
    "    # see if there are categorical data\n",
    "    print(\"\\nCategorical features:\", df.select_dtypes(include=['O']).columns.tolist())\n",
    "    \n",
    "    # Check NA values\n",
    "    # Check any number of columns with NaN\n",
    "    print(\"\\nColumns with NaN: \", df.isnull().any().sum(), ' / ', len(df.columns))\n",
    "\n",
    "    # Check any number of data points with NaN\n",
    "    print(\"\\nNumber of data points with NaN:\", df.isnull().any(axis=1).sum(), ' / ', len(df))\n",
    "    \n",
    "    # List of values per column\n",
    "    print()\n",
    "    for column in df.columns:\n",
    "        print(column + \" -> \")\n",
    "        print(df[column].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCheckings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be92502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicates\n",
    "\n",
    "print(\"Number of duplicates: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b6ddb",
   "metadata": {},
   "source": [
    "### Encoding of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "import transformers as tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63c499",
   "metadata": {},
   "source": [
    "#### Filter Operating Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OSes\n",
    "df = df[df.os.isin(['Linux', 'Windows', 'Mac OS X', 'Solaris', 'OpenBSD', 'FreeBSD'])]\n",
    "df.replace({'os': {'FreeBSD': 'BSD', 'OpenBSD': 'BSD'}}, inplace=True)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Drop version column\n",
    "df.drop([\"version\",\"sig_direction\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f186fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# TTL, MSS & Windows size\n",
    "\n",
    "# ttl_factor = 10\n",
    "\n",
    "# array = df.to_numpy()\n",
    "# ttl_i = df.columns.get_loc('initial_ttl')\n",
    "\n",
    "# for row in array:\n",
    "#     for i in range(1,ttl_factor+1):\n",
    "#         new_row = row.copy()\n",
    "#         new_row[ttl_i] = row[ttl_i] - i\n",
    "        \n",
    "#         array = np.vstack((array, new_row))\n",
    "        \n",
    "# df = pd.DataFrame(array, columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f18ef",
   "metadata": {},
   "source": [
    "#### TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6b739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TTL\n",
    "# Numeric value\n",
    "\n",
    "encoder_ttl = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e09dd",
   "metadata": {},
   "source": [
    "#### MSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd8cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MSS\n",
    "# Categorical encoding\n",
    "\n",
    "# encoder_mss = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')\n",
    "df.drop('mss', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c7abd",
   "metadata": {},
   "source": [
    "#### Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Size\n",
    "\n",
    "encoder_window_size = tr.WindowSizeTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac872d9d",
   "metadata": {},
   "source": [
    "#### Windows Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86414ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Scaling \n",
    "# Categorical encoding\n",
    "\n",
    "encoder_window_scaling = OneHotEncoder(drop=['*'], sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed765f3",
   "metadata": {},
   "source": [
    "#### TCP options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Options\n",
    "# Custom transformer\n",
    "\n",
    "encoder_tcp_options = tr.TCPOptionsTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d48d9",
   "metadata": {},
   "source": [
    "#### Quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quirks\n",
    "# Categorical encoding (already encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfb41b",
   "metadata": {},
   "source": [
    "#### Applying encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encodings\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "encoders = make_column_transformer(\n",
    "    (encoder_ttl, ['initial_ttl']),\n",
    "    (encoder_window_size, ['window_size']),\n",
    "    (encoder_window_scaling, ['window_scaling']),\n",
    "    (encoder_tcp_options, ['tcp_options']),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "transformed = encoders.fit_transform(df)\n",
    "transformed_df = pd.DataFrame(\n",
    "    transformed,\n",
    "    columns=encoders.get_feature_names_out()\n",
    ")\n",
    "\n",
    "df = transformed_df\n",
    "\n",
    "# define output variable name\n",
    "OutVar = df.os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCheckings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47eee06",
   "metadata": {},
   "source": [
    "#### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ec281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two datasets: requests and responses\n",
    "\n",
    "# df = df[df.sig_direction.isin(['request'])].drop('sig_direction', axis=1)\n",
    "# df_response = df[df.sig_direction.isin(['response'])].drop('sig_direction', axis=1)\n",
    "\n",
    "# df.reset_index(inplace=True, drop=True)\n",
    "# df_response.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509e59c",
   "metadata": {},
   "source": [
    "### Verify the classes ballance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[OutVar].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acecf5",
   "metadata": {},
   "source": [
    "### Get data as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea03bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request\n",
    "\n",
    "Ydata = df[OutVar].values                  # get values of features\n",
    "Xdata = df.drop(OutVar,axis = 1).values    # get output values\n",
    "\n",
    "print('Shape X data:', Xdata.shape)\n",
    "print('Shape Y data:',Ydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959ba23",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Request\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata,\n",
    "#                                                                     stratify=Ydata, \n",
    "#                                                                     test_size=0.10,\n",
    "#                                                                     random_state=seed)\n",
    "\n",
    "# # verify dimentions of data for training and test\n",
    "# print('Shape X_train:', X_train.shape)\n",
    "# print('Shape X_test:' , X_test.shape)\n",
    "# print('Shape y_train:', y_train.shape)\n",
    "# print('Shape y_test:' , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b84adb",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac6edb",
   "metadata": {},
   "source": [
    "##### Classes balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69552527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(class_weight=option, classes=np.unique(y_data), y=y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w\n",
    "\n",
    "class_weights = set_weights(Ydata)\n",
    "\n",
    "print(\"Request balance => \",class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e86d5",
   "metadata": {},
   "source": [
    "##### Classifiers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dec07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of classifiers to train as baseline classifiers\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(), # No random_state\n",
    "    LogisticRegression(n_jobs=-1,solver='lbfgs',random_state=seed,class_weight=class_weights),\n",
    "    MLPClassifier(hidden_layer_sizes= (30), random_state = seed, shuffle=False, solver='adam',activation='relu',batch_size=500, max_iter=5000),\n",
    "    DecisionTreeClassifier(random_state=seed,class_weight=class_weights),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "    BaggingClassifier(n_jobs=-1,random_state=seed)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4d01c",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold\n",
    "\n",
    "hiper_k_rango = range(1,30)\n",
    "scores=[]\n",
    "RKFold_stratified = RepeatedStratifiedKFold(n_splits=10,n_repeats=50)\n",
    "\n",
    "for k in hiper_k_rango:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    resultados_kfold = cross_val_score(knn_model,Xdata,Ydata,cv=RKFold_stratified,scoring='accuracy')\n",
    "    scores.append(resultados_kfold.mean())\n",
    "    \n",
    "scores_media_Kfold = scores\n",
    "\n",
    "print(scores)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(hiper_k_rango,scores)\n",
    "plt.xlabel(\"Valores de k\")\n",
    "plt.ylabel(\"Accuracy en 50 repeticiones 10-fold cross-validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bfa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20530004",
   "metadata": {},
   "source": [
    "### Export transformers & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae085e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "# # Transformers\n",
    "# dump(encoders, '../../persistence/p0f/p0f_encoders.joblib')\n",
    "\n",
    "# # Models\n",
    "# dump(models_ML.Model.values[2],'../../persistence/p0f/p0f_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641d8269f063d1dd6b8e5de571a838aa2a022ace140349eaf6f3c271c01e6aeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
